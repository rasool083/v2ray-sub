import requests
import re
import base64
import json
import urllib.parse
from bs4 import BeautifulSoup
import logging

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯ Ø¨Ù‡ØªØ± Ø¯Ø± GitHub Actions ---
logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ---
# URL Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§
TELEGRAM_CHANNEL_URL = "https://t.me/s/ConfigsHubPlus"
# Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø± Ù‡Ø± Ø¨Ø§Ø± Ø§Ø¬Ø±Ø§
MAX_CONFIGS = 400
# Ù†Ø§Ù… Ø¬Ø¯ÛŒØ¯ÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ù¾Ø±Ú†Ù… Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¶Ø§ÙÙ‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯)
NEW_CONFIG_NAME = "t.me/rghoddoosi Ø±Ø³ÙˆÙ„ Ù‚Ø¯ÙˆØ³ÛŒ"
# Ù‡Ø¯Ø± User-Agent Ø¨Ø±Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ÛŒÚ© Ù…Ø±ÙˆØ±Ú¯Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ùˆ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù„Ø§Ú© Ø´Ø¯Ù†
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'
}
# Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª (Ø¨Ù‡ Ø«Ø§Ù†ÛŒÙ‡)
REQUEST_TIMEOUT = 25

def extract_flag_from_name(name: str) -> str:
    """
    ÛŒÚ© Ù†Ø§Ù… Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯Ù‡ Ùˆ Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ù¾Ø±Ú†Ù… Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ú©Ø´ÙˆØ± Ø±Ø§ Ø§Ø² Ø¢Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†Ø¯.
    Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø±Ø§ÛŒØ¬ Ù…Ø§Ù†Ù†Ø¯ [ğŸ‡¨ğŸ‡¦] ÛŒØ§ ğŸ‡ºğŸ‡¸ Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    # Ø§Ù„Ú¯Ùˆ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ú†Ù… Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ø± Ø¨Ø±Ø§Ú©Øª Ø¨Ø§Ø´Ù†Ø¯ ÛŒØ§ Ù†Ø¨Ø§Ø´Ù†Ø¯
    flag_pattern = r'(\[[A-Z]{2}\])|([ğŸ‡¦-ğŸ‡¿]{2})'
    match = re.search(flag_pattern, name, re.IGNORECASE)
    if match:
        # Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø§ÙˆÙ„ÛŒÙ† Ú¯Ø±ÙˆÙ‡ Ù¾ÛŒØ¯Ø§ Ø´Ø¯Ù‡ Ú©Ù‡ Ø®Ø§Ù„ÛŒ Ù†ÛŒØ³Øª
        return next((group for group in match.groups() if group is not None), "ğŸ‡®ğŸ‡·")
    return "ğŸ‡®ğŸ‡·" # Ù¾Ø±Ú†Ù… Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÛŒØ§ÙØªÙ†

def process_config(config_str: str) -> str | None:
    """
    ÛŒÚ© Ø±Ø´ØªÙ‡ Ú©Ø§Ù†ÙÛŒÚ¯ Ø®Ø§Ù… Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø±Ø¯Ù‡ØŒ Ù†Ø§Ù… Ø¢Ù† Ø±Ø§ ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ Ú©Ø§Ù†ÙÛŒÚ¯ Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ú©Ø§Ù†ÙÛŒÚ¯ØŒ None Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    try:
        # --- Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Vmess ---
        if config_str.startswith("vmess://"):
            try:
                # Ø§ÙØ²ÙˆØ¯Ù† padding ØµØ­ÛŒØ­ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ Base64
                b64_part = config_str[8:]
                padded_b64 = b64_part + '=' * (-len(b64_part) % 4)
                decoded_json = base64.b64decode(padded_b64).decode('utf-8')
                config_data = json.loads(decoded_json)
                
                original_ps = config_data.get('ps', '')
                flag = extract_flag_from_name(original_ps)
                
                config_data['ps'] = f"{flag} {NEW_CONFIG_NAME}"
                
                new_json = json.dumps(config_data, ensure_ascii=False, separators=(',', ':'))
                new_b64 = base64.b64encode(new_json.encode('utf-8')).decode('utf-8')
                return "vmess://" + new_b64
            except (json.JSONDecodeError, base64.Error, UnicodeDecodeError) as e:
                logging.warning(f"Ú©Ø§Ù†ÙÛŒÚ¯ Vmess Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯: {config_str[:30]}... | Ø®Ø·Ø§: {e}")
                return None

        # --- Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Vless, Trojan, SS ---
        elif any(config_str.startswith(p) for p in ["vless://", "trojan://", "ss://"]):
            parts = config_str.split("#", 1)
            base_config = parts[0]
            
            # Ø§Ú¯Ø± Ú©Ø§Ù†ÙÛŒÚ¯ ÙØ§Ù‚Ø¯ Ø¨Ø¯Ù†Ù‡ Ø§ØµÙ„ÛŒ Ø¨ÙˆØ¯ØŒ Ø¢Ù† Ø±Ø§ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø¯Ø§Ù†
            if not base_config:
                return None

            old_name = urllib.parse.unquote(parts[1]) if len(parts) > 1 else ""
            flag = extract_flag_from_name(old_name)
            
            # Ø³Ø§Ø®Øª Ù†Ø§Ù… Ø¬Ø¯ÛŒØ¯ Ùˆ Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ ØµØ­ÛŒØ­ Ø¢Ù† Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± URL
            new_name_encoded = urllib.parse.quote(f"{flag} {NEW_CONFIG_NAME}")
            
            return f"{base_config}#{new_name_encoded}"
        
        else:
            # Ø§Ú¯Ø± Ù¾Ø±ÙˆØªÚ©Ù„ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±
            return None

    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù†ÙÛŒÚ¯: {config_str[:30]}... | Ø®Ø·Ø§: {e}")
        return None

def scrape_telegram_channel():
    """
    ØµÙØ­Ø§Øª Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    all_configs = []
    current_url = TELEGRAM_CHANNEL_URL
    processed_urls = set() # Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§ÙØªØ§Ø¯Ù† Ø¯Ø± Ø­Ù„Ù‚Ù‡ Ø¨ÛŒâ€ŒÙ†Ù‡Ø§ÛŒØª

    while current_url and len(all_configs) < MAX_CONFIGS:
        if current_url in processed_urls:
            logging.warning("URL ØªÚ©Ø±Ø§Ø±ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯ØŒ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            break
        
        logging.info(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡: {current_url}")
        processed_urls.add(current_url)

        try:
            response = requests.get(current_url, headers=HEADERS, timeout=REQUEST_TIMEOUT)
            response.raise_for_status() # Ø§Ú¯Ø± Ú©Ø¯ ÙˆØ¶Ø¹ÛŒØª Ø®Ø·Ø§ Ø¨ÙˆØ¯ (Ù…Ø«Ù„ 404 ÛŒØ§ 500)ØŒ Ø§Ø³ØªØ«Ù†Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø§Ø² ØªÚ¯â€ŒÙ‡Ø§ÛŒ <code> Ú©Ù‡ Ø±ÙˆØ´ÛŒ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ø³Øª
            code_blocks = soup.find_all("code")
            for block in code_blocks:
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² splitlines Ø¨Ø±Ø§ÛŒ Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ Ø¯Ø± ÛŒÚ© Ø¨Ù„ÙˆÚ© Ú©Ø¯ Ø¨Ø§Ø´Ù†Ø¯
                for line in block.get_text(strip=True).splitlines():
                    clean_line = line.strip()
                    if any(clean_line.startswith(p) for p in ["vmess://", "vless://", "trojan://", "ss://"]):
                        processed = process_config(clean_line)
                        if processed:
                            all_configs.append(processed)
                        if len(all_configs) >= MAX_CONFIGS:
                            break
                if len(all_configs) >= MAX_CONFIGS:
                    break
            
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù„ÛŒÙ†Ú© "Older posts" Ø¨Ø±Ø§ÛŒ Ø±ÙØªÙ† Ø¨Ù‡ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯
            older_posts_link = soup.find('a', class_='tgme_widget_message_more', attrs={'href': True})
            if older_posts_link:
                current_url = "https://t.me" + older_posts_link['href']
            else:
                logging.info("Ø¨Ù‡ Ø§Ù†ØªÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„ Ø±Ø³ÛŒØ¯ÛŒÙ…. Ù„ÛŒÙ†Ú© 'Older posts' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                current_url = None # Ù¾Ø§ÛŒØ§Ù† Ù¾ÛŒÙ…Ø§ÛŒØ´

        except requests.exceptions.RequestException as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…: {e}")
            break # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ØŒ Ø¹Ù…Ù„ÛŒØ§Øª Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯
    
    # Ø­Ø°Ù Ù…ÙˆØ§Ø±Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨Ø§ Ø­ÙØ¸ ØªØ±ØªÛŒØ¨ Ùˆ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ ØªØ¹Ø¯Ø§Ø¯ Ø­Ø¯Ø§Ú©Ø«Ø±
    unique_configs = list(dict.fromkeys(all_configs))
    return unique_configs[:MAX_CONFIGS]

def main():
    """ ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ """
    logging.info("--- Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯ V2Ray ---")
    
    try:
        final_configs = scrape_telegram_channel()
        
        if not final_configs:
            logging.warning("Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. ÙØ§ÛŒÙ„ sub.txt Ø¨Ø§ Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ Ø¨Ù‡â€ŒØ±ÙˆØ² Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            content = "âš ï¸ Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù„Ø­Ø¸Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        else:
            logging.info(f"ØªØ¹Ø¯Ø§Ø¯ {len(final_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ ÛŒØ§ÙØª Ø´Ø¯.")
            content = "\n".join(final_configs)
            
        # Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù„ Ù…Ø­ØªÙˆØ§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ Base64
        encoded_content = base64.b64encode(content.encode('utf-8')).decode('utf-8')

    except Exception as e:
        logging.error(f"ÛŒÚ© Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ†Ø´Ø¯Ù‡ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø±Ø® Ø¯Ø§Ø¯: {e}")
        error_message = f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª: {e}"
        encoded_content = base64.b64encode(error_message.encode('utf-8')).decode('utf-8')

    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ sub.txt
    with open("sub.txt", "w", encoding="utf-8") as f:
        f.write(encoded_content)
    
    logging.info(f"--- Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. ÙØ§ÛŒÙ„ sub.txt Ø¨Ø§ {len(encoded_content)} Ø¨Ø§ÛŒØª Ø¨Ù‡â€ŒØ±ÙˆØ² Ø´Ø¯. ---")

if __name__ == "__main__":
    main()
    
