import requests
import re
import base64
import json
import urllib.parse
from bs4 import BeautifulSoup
import logging

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯ Ø¨Ù‡ØªØ± Ø¯Ø± GitHub Actions ---
logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ---
TELEGRAM_CHANNEL_URL = "https://t.me/s/ConfigsHubPlus"
MAX_CONFIGS = 400
NEW_CONFIG_NAME = "t.me/rghoddoosi Ø±Ø³ÙˆÙ„ Ù‚Ø¯ÙˆØ³ÛŒ"
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'
}
REQUEST_TIMEOUT = 25

def is_config_valid(config_str: str) -> bool:
    """
    ÛŒÚ© Ø±Ø´ØªÙ‡ Ú©Ø§Ù†ÙÛŒÚ¯ Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯Ù‡ Ùˆ Ø³Ø§Ø®ØªØ§Ø± Ø§ÙˆÙ„ÛŒÙ‡ Ø¢Ù† Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø§Ø² ØªÙˆÙ‚Ù Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± V2RayNG Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ ÛŒÚ© Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    if not config_str:
        return False
    
    try:
        # --- Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Vless Ùˆ Trojan ---
        if config_str.startswith("vless://") or config_str.startswith("trojan://"):
            # Ø­Ø¯Ø§Ù‚Ù„ Ø¨Ø±Ø±Ø³ÛŒ: Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ ÛŒÚ© UUID Ùˆ Ø¹Ù„Ø§Ù…Øª @ Ø¨Ø§Ø´Ø¯.
            # Ø§Ù„Ú¯ÙˆÛŒ UUID: 8-4-4-4-12 Ú©Ø§Ø±Ø§Ú©ØªØ± Ù‡Ú¯Ø²Ø§Ø¯Ø³ÛŒÙ…Ø§Ù„
            uuid_pattern = r'[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}'
            if '@' in config_str and re.search(uuid_pattern, config_str):
                return True
            logging.warning(f"Ø³Ø§Ø®ØªØ§Ø± Vless/Trojan Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª: {config_str[:40]}...")
            return False

        # --- Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Vmess ---
        elif config_str.startswith("vmess://"):
            b64_part = config_str[8:]
            padded_b64 = b64_part + '=' * (-len(b64_part) % 4)
            decoded_json = base64.b64decode(padded_b64).decode('utf-8')
            data = json.loads(decoded_json)
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø¯Ø± Ú©Ø§Ù†ÙÛŒÚ¯ Vmess
            if all(key in data for key in ['add', 'port', 'id', 'ps']):
                return True
            logging.warning(f"ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Vmess ÛŒØ§ÙØª Ù†Ø´Ø¯: {config_str[:30]}...")
            return False
            
        # --- Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ SS (Ø¨Ø³ÛŒØ§Ø± Ø³Ø§Ø¯Ù‡) ---
        elif config_str.startswith("ss://"):
             # Ø­Ø¯Ø§Ù‚Ù„ Ø¨Ø±Ø±Ø³ÛŒ: Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ø¹Ù„Ø§Ù…Øª @ Ùˆ # Ø¨Ø§Ø´Ø¯
            if '@' in config_str and '#' in config_str:
                return True
            logging.warning(f"Ø³Ø§Ø®ØªØ§Ø± SS Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª: {config_str[:40]}...")
            return False

    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯: {config_str[:40]}... | Ø®Ø·Ø§: {e}")
        return False
    
    return False


def extract_flag_from_name(name: str) -> str:
    """
    ÛŒÚ© Ù†Ø§Ù… Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯Ù‡ Ùˆ Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ù¾Ø±Ú†Ù… Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ú©Ø´ÙˆØ± Ø±Ø§ Ø§Ø² Ø¢Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†Ø¯.
    """
    flag_pattern = r'(\[[A-Z]{2}\])|([ğŸ‡¦-ğŸ‡¿]{2})'
    match = re.search(flag_pattern, name, re.IGNORECASE)
    if match:
        return next((group for group in match.groups() if group is not None), "ğŸ‡®ğŸ‡·")
    return "ğŸ‡®ğŸ‡·"

def process_config(config_str: str) -> str | None:
    """
    ÛŒÚ© Ø±Ø´ØªÙ‡ Ú©Ø§Ù†ÙÛŒÚ¯ Ø®Ø§Ù… Ù…Ø¹ØªØ¨Ø± Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø±Ø¯Ù‡ Ùˆ Ù†Ø§Ù… Ø¢Ù† Ø±Ø§ ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
    """
    try:
        if config_str.startswith("vmess://"):
            b64_part = config_str[8:]
            padded_b64 = b64_part + '=' * (-len(b64_part) % 4)
            decoded_json = base64.b64decode(padded_b64).decode('utf-8')
            config_data = json.loads(decoded_json)
            original_ps = config_data.get('ps', '')
            flag = extract_flag_from_name(original_ps)
            config_data['ps'] = f"{flag} {NEW_CONFIG_NAME}"
            new_json = json.dumps(config_data, ensure_ascii=False, separators=(',', ':'))
            new_b64 = base64.b64encode(new_json.encode('utf-8')).decode('utf-8')
            return "vmess://" + new_b64
        else:
            parts = config_str.split("#", 1)
            base_config = parts[0]
            old_name = urllib.parse.unquote(parts[1]) if len(parts) > 1 else ""
            flag = extract_flag_from_name(old_name)
            new_name_encoded = urllib.parse.quote(f"{flag} {NEW_CONFIG_NAME}")
            return f"{base_config}#{new_name_encoded}"
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø±: {config_str[:30]}... | Ø®Ø·Ø§: {e}")
        return None

def scrape_telegram_channel():
    """
    ØµÙØ­Ø§Øª Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    all_configs = []
    current_url = TELEGRAM_CHANNEL_URL
    processed_urls = set()

    while current_url and len(all_configs) < MAX_CONFIGS:
        if current_url in processed_urls:
            logging.warning("URL ØªÚ©Ø±Ø§Ø±ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯ØŒ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            break
        
        logging.info(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡: {current_url}")
        processed_urls.add(current_url)

        try:
            response = requests.get(current_url, headers=HEADERS, timeout=REQUEST_TIMEOUT)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            code_blocks = soup.find_all("code")
            for block in code_blocks:
                for line in block.get_text(strip=True).splitlines():
                    clean_line = line.strip()
                    
                    # --- Ù…Ø±Ø­Ù„Ù‡ Ø¬Ø¯ÛŒØ¯: Ø§ÙˆÙ„ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒØŒ Ø³Ù¾Ø³ Ù¾Ø±Ø¯Ø§Ø²Ø´ ---
                    if is_config_valid(clean_line):
                        processed = process_config(clean_line)
                        if processed:
                            all_configs.append(processed)
                    
                    if len(all_configs) >= MAX_CONFIGS:
                        break
                if len(all_configs) >= MAX_CONFIGS:
                    break
            
            older_posts_link = soup.find('a', class_='tgme_widget_message_more', attrs={'href': True})
            if older_posts_link:
                current_url = "https://t.me" + older_posts_link['href']
            else:
                logging.info("Ø¨Ù‡ Ø§Ù†ØªÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„ Ø±Ø³ÛŒØ¯ÛŒÙ….")
                current_url = None

        except requests.exceptions.RequestException as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…: {e}")
            break
    
    unique_configs = list(dict.fromkeys(all_configs))
    return unique_configs[:MAX_CONFIGS]

def main():
    logging.info("--- Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯ V2Ray (Ù†Ø³Ø®Ù‡ Ø¨Ø§ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ) ---")
    
    try:
        final_configs = scrape_telegram_channel()
        
        if not final_configs:
            logging.warning("Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            content = "âš ï¸ Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù„Ø­Ø¸Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        else:
            logging.info(f"ØªØ¹Ø¯Ø§Ø¯ {len(final_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø± Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ø´Ø¯.")
            content = "\n".join(final_configs)
            
        encoded_content = base64.b64encode(content.encode('utf-8')).decode('utf-8')

    except Exception as e:
        logging.error(f"ÛŒÚ© Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ†Ø´Ø¯Ù‡ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø±Ø® Ø¯Ø§Ø¯: {e}")
        error_message = f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª: {e}"
        encoded_content = base64.b64encode(error_message.encode('utf-8')).decode('utf-8')

    with open("sub.txt", "w", encoding="utf-8") as f:
        f.write(encoded_content)
    
    logging.info(f"--- Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. ÙØ§ÛŒÙ„ sub.txt Ø¨Ø§ {len(encoded_content)} Ø¨Ø§ÛŒØª Ø¨Ù‡â€ŒØ±ÙˆØ² Ø´Ø¯. ---")

if __name__ == "__main__":
    main()
    
