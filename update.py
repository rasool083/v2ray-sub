import requests
import re
import base64
import json
import urllib.parse
from bs4 import BeautifulSoup
import logging
import time
from datetime import datetime, timezone

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ ---
logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ ---
TELEGRAM_CHANNEL_URL = "https://t.me/s/ConfigsHub"
MAX_CONFIGS = 400
NEW_CONFIG_NAME = "t.me/rghoddoosi Ø±Ø³ÙˆÙ„ Ù‚Ø¯ÙˆØ³ÛŒ"
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36',
    'Accept-Language': 'en-US,en;q=0.9'
}
REQUEST_TIMEOUT = 30

def save_debug_html(content):
    """Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ØŒ Ù…Ø­ØªÙˆØ§ÛŒ HTML ØµÙØ­Ù‡ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    with open("debug_page.html", "w", encoding="utf-8") as f:
        f.write(content)
    logging.info("Ù…Ø­ØªÙˆØ§ÛŒ HTML ØµÙØ­Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯ Ø¯Ø± 'debug_page.html' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

def is_config_valid(config_str: str) -> bool:
    """Ø³Ø§Ø®ØªØ§Ø± Ø§ÙˆÙ„ÛŒÙ‡ Ú©Ø§Ù†ÙÛŒÚ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯Ù† Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    if not config_str: return False
    try:
        if config_str.startswith(("vless://", "trojan://")):
            uuid_pattern = r'[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}'
            return '@' in config_str and re.search(uuid_pattern, config_str) is not None
        elif config_str.startswith("vmess://"):
            b64_part = config_str[8:]
            data = json.loads(base64.b64decode(b64_part + '==').decode('utf-8'))
            return all(key in data for key in ['add', 'port', 'id'])
        elif config_str.startswith("ss://"):
            return '@' in config_str and '#' in config_str
    except Exception:
        return False
    return False

def extract_flag_from_name(name: str) -> str:
    """Ù¾Ø±Ú†Ù… Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ú©Ø´ÙˆØ± Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    flag_pattern = r'(\[[A-Z]{2}\])|([ğŸ‡¦-ğŸ‡¿]{2})'
    match = re.search(flag_pattern, name, re.IGNORECASE)
    return next((g for g in match.groups() if g), "ğŸ‡®ğŸ‡·") if match else "ğŸ‡®ğŸ‡·"

def process_config(config_str: str) -> str | None:
    """ÛŒÚ© Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø± Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ù†Ø§Ù… Ø¢Ù† Ø±Ø§ ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒØ¯Ù‡Ø¯."""
    try:
        if config_str.startswith("vmess://"):
            b64_part = config_str[8:]
            config_data = json.loads(base64.b64decode(b64_part + '==').decode('utf-8'))
            flag = extract_flag_from_name(config_data.get('ps', ''))
            config_data['ps'] = f"{flag} {NEW_CONFIG_NAME}"
            new_json = json.dumps(config_data, ensure_ascii=False, separators=(',', ':'))
            return "vmess://" + base64.b64encode(new_json.encode('utf-8')).decode('utf-8')
        else:
            parts = config_str.split("#", 1)
            base_config, old_name = parts[0], (urllib.parse.unquote(parts[1]) if len(parts) > 1 else "")
            flag = extract_flag_from_name(old_name)
            new_name_encoded = urllib.parse.quote(f"{flag} {NEW_CONFIG_NAME}")
            return f"{base_config}#{new_name_encoded}"
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù†ÙÛŒÚ¯: {config_str[:30]}... | Ø®Ø·Ø§: {e}")
        return None

def scrape_telegram_channel():
    """ØµÙØ­Ø§Øª Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø±Ø§ Ø¨Ø§ Ù…Ù†Ø·Ù‚ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ØŒ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    all_configs = []
    next_page_param = ""
    
    for page_num in range(1, 31): # Ø­Ø¯Ø§Ú©Ø«Ø± 30 ØµÙØ­Ù‡
        if len(all_configs) >= MAX_CONFIGS:
            logging.info(f"Ø¨Ù‡ Ø³Ù‚Ù {MAX_CONFIGS} Ú©Ø§Ù†ÙÛŒÚ¯ Ø±Ø³ÛŒØ¯ÛŒÙ…. Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            break

        full_url = TELEGRAM_CHANNEL_URL + next_page_param
        logging.info(f"--- Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡ {page_num}: {full_url} ---")

        try:
            response = requests.get(full_url, headers=HEADERS, timeout=REQUEST_TIMEOUT)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            code_blocks = soup.find_all("code")
            if not code_blocks and page_num == 1:
                logging.warning("Ù‡ÛŒÚ† ØªÚ¯ <code> Ø¯Ø± ØµÙØ­Ù‡ Ø§ÙˆÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø³Ø§Ø®ØªØ§Ø± ØªÙ„Ú¯Ø±Ø§Ù… ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡ Ø¨Ø§Ø´Ø¯.")
                save_debug_html(response.text)

            found_in_page = 0
            for block in code_blocks:
                for line in block.get_text(strip=True).splitlines():
                    if is_config_valid(line.strip()):
                        if (processed := process_config(line.strip())):
                            all_configs.append(processed)
                            found_in_page += 1
            
            logging.info(f"ØªØ¹Ø¯Ø§Ø¯ {found_in_page} Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø± Ø¯Ø± Ø§ÛŒÙ† ØµÙØ­Ù‡ ÛŒØ§ÙØª Ø´Ø¯.")

            # --- Ù…Ù†Ø·Ù‚ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ Ùˆ Ù…Ù‚Ø§ÙˆÙ… ---
            if not (older_posts_link := soup.select_one('a.tgme_widget_message_more[href^="?before="]')):
                logging.info("Ø¨Ù‡ Ø§Ù†ØªÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„ Ø±Ø³ÛŒØ¯ÛŒÙ… ÛŒØ§ Ù„ÛŒÙ†Ú© ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù¾Ø§ÛŒØ§Ù† Ù¾ÛŒÙ…Ø§ÛŒØ´.")
                break
            
            next_page_param = older_posts_link['href']
            time.sleep(1)

        except requests.exceptions.RequestException as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…: {e}")
            # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³ØªØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ… HTML Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†ÛŒÙ…
            if 'response' in locals() and hasattr(response, 'text'):
                save_debug_html(response.text)
            break
    
    return list(dict.fromkeys(all_configs))[:MAX_CONFIGS]

def main():
    logging.info("--- Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ (Ù†Ø³Ø®Ù‡ Ø¨Ø§ Ø¯ÛŒØ¨Ø§Ú¯ Ùˆ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡) ---")
    try:
        final_configs = scrape_telegram_channel()
        
        # --- Ø§ÙØ²ÙˆØ¯Ù† Timestamp Ø¨Ø±Ø§ÛŒ ØªØ¶Ù…ÛŒÙ† ØªØºÛŒÛŒØ± ÙØ§ÛŒÙ„ ---
        utc_now = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S %Z")
        comment_line = f"# Updated on: {utc_now}"
        
        if not final_configs:
            logging.warning("Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            content = f"{comment_line}\n# âš ï¸ Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù„Ø­Ø¸Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        else:
            logging.info(f"Ù…Ø¬Ù…ÙˆØ¹Ø§Ù‹ {len(final_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ùˆ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ ÛŒØ§ÙØª Ø´Ø¯.")
            # Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† Ú©Ø§Ù…Ù†Øª Ø²Ù…Ø§Ù† Ø¯Ø± Ø¨Ø§Ù„Ø§ÛŒ Ù„ÛŒØ³Øª Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§
            content_list = [comment_line] + final_configs
            content = "\n".join(content_list)
            
        encoded_content = base64.b64encode(content.encode('utf-8')).decode('utf-8')

    except Exception as e:
        logging.error(f"ÛŒÚ© Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ†Ø´Ø¯Ù‡ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø±Ø® Ø¯Ø§Ø¯: {e}", exc_info=True)
        error_message = f"# Updated on: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S %Z')}\n# âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª: {e}"
        encoded_content = base64.b64encode(error_message.encode('utf-8')).decode('utf-8')

    with open("sub.txt", "w", encoding="utf-8") as f:
        f.write(encoded_content)
    logging.info("--- Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. ÙØ§ÛŒÙ„ sub.txt Ø¨Ù‡â€ŒØ±ÙˆØ² Ø´Ø¯. ---")

if __name__ == "__main__":
    main()
    
